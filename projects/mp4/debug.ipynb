{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aafa31b-7ca1-4b38-9f79-412f33165afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parent:\n",
    "    def twice(self):\n",
    "        self.message()\n",
    "        self.message()\n",
    "        \n",
    "    def message(self):\n",
    "        print(\"parent says hi\")\n",
    "        \n",
    "class Child(Parent):\n",
    "    def message(self):\n",
    "        print(\"child says hi\")\n",
    "        \n",
    "c = Child()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a11102a-69a0-4753-81f8-f0753104209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child says hi\n",
      "child says hi\n"
     ]
    }
   ],
   "source": [
    "#if we run c.twice() then it will try to find the method in the class Child but will not be able to find it so it will go to he parent class and will\n",
    "# be able to find he method definition there and will call this method from the parent class\n",
    "# so it will print child says hi 2 times BECAUSE the twice() method will use TYPE-BASED DISPATCH methodology to call the appropriate message()\n",
    "# method on the object which is trying to call this method and that is the child class's objec whose reference is given by the self pointer\n",
    "c.twice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb1e355-2ee5-41b2-9bef-ab706e53593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphSearcher:\n",
    "    def __init__(self):\n",
    "        self.visited = set()\n",
    "        self.order = []\n",
    "\n",
    "    def visit_and_get_children(self, node):\n",
    "        \"\"\"Must be overridden in subclasses.\"\"\"\n",
    "        raise Exception(\"must be overridden in sub classes -- don't change me here!\")\n",
    "\n",
    "    def dfs_search(self, node):\n",
    "        # 1. clear out visited set and order list\n",
    "        self.visited.clear()\n",
    "        self.order.clear()\n",
    "        # 2. start recursive search\n",
    "        self.dfs_visit(node)\n",
    "\n",
    "    def dfs_visit(self, node):\n",
    "        # 1. if this node has already been visited, just return\n",
    "        if node in self.visited:\n",
    "            return\n",
    "        # 2. mark node as visited\n",
    "        self.visited.add(node)\n",
    "        # 3. record and get children\n",
    "        children = self.visit_and_get_children(node)\n",
    "        # 4. visit each child\n",
    "        for child in children:\n",
    "            self.dfs_visit(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a8c27-0e56-4423-8515-fd28065460e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "must be overridden in sub classes -- don't change me here!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m g \u001b[38;5;241m=\u001b[39m GraphSearcher()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdfs_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36mGraphSearcher.dfs_search\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 2. start recursive search\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdfs_visit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m, in \u001b[0;36mGraphSearcher.dfs_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 3. record and get children\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit_and_get_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 4. visit each child\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m children:\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mGraphSearcher.visit_and_get_children\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvisit_and_get_children\u001b[39m(\u001b[38;5;28mself\u001b[39m, node):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Must be overridden in subclasses.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be overridden in sub classes -- don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change me here!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: must be overridden in sub classes -- don't change me here!"
     ]
    }
   ],
   "source": [
    "g = GraphSearcher()\n",
    "g.dfs_search(\"A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae24d64-6e11-45ff-91e9-0cc6b6b14625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    [0,1,0,1,0,1,0,0,1],\n",
    "    [0,0,1,0,1,1,0,1,0],\n",
    "    [0,0,0,1,0,1,1,1,0],\n",
    "    [0,0,1,0,1,0,0,1,1],\n",
    "    [0,1,0,0,0,1,1,0,0],\n",
    "    [1,1,0,0,1,0,0,1,1],\n",
    "    [1,1,1,0,1,1,1,0,0],\n",
    "    [0,1,0,0,0,1,1,0,1],\n",
    "    [0,1,0,1,0,0,1,1,1],\n",
    "], index=[\"A\", \"B\", \"C\", \"D\",\"E\",\"F\",\"G\",\"H\",\"I\"], columns=[\"A\", \"B\", \"C\", \"D\",\"E\",\"F\",\"G\",\"H\",\"I\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4592932a-ac6e-41ce-991c-101520bc8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, has_edge in df.loc[\"B\"].items():\n",
    "    if has_edge:\n",
    "        print(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f8c5f-f52f-4b4c-96e4-654855e4f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixSearcher(GraphSearcher):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()            # call parent constructor\n",
    "        self.df = df\n",
    "\n",
    "    def visit_and_get_children(self, node):\n",
    "        # Record the node value in self.order\n",
    "        self.order.append(node)\n",
    "        children = []\n",
    "        # Use `self.df` to determine what children the node has and append them\n",
    "        for col, has_edge in self.df.loc[node].items():\n",
    "            if has_edge == 1:\n",
    "                children.append(col)\n",
    "        return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740eb1f-b5d0-48d2-a6e4-4d9fef36171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MatrixSearcher(df)\n",
    "m.dfs_search(\"E\")\n",
    "m.order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3da193-7fb0-415b-8203-1fd5e0e68f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import deque \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b90a5-239d-4e0c-9283-ae5803d4c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSearcher:\n",
    "    def __init__(self):\n",
    "        # tracks which nodes have been visited\n",
    "        self.visited = set()\n",
    "        # records the order in which nodes are first seen\n",
    "        self.order = []\n",
    "\n",
    "    def visit_and_get_children(self, node):\n",
    "        \"\"\"\n",
    "        MUST be overridden in subclasses.\n",
    "        Should append `node` to self.order and return an iterable\n",
    "        of its children.\n",
    "        \"\"\"\n",
    "        raise Exception(\"must be overridden in sub classes -- don't change me here!\")\n",
    "\n",
    "    def dfs_search(self, start_node):\n",
    "        \"\"\"\n",
    "        Public entry point: clears state, kicks off the recursion,\n",
    "        and returns the final visitation order.\n",
    "        \"\"\"\n",
    "        # reset visited & order\n",
    "        self.visited.clear()\n",
    "        self.order.clear()\n",
    "\n",
    "        # start the recursive DFS\n",
    "        self.dfs_visit(start_node)\n",
    "\n",
    "        # return the recorded order\n",
    "        return self.order\n",
    "\n",
    "    def dfs_visit(self, node):\n",
    "        \"\"\"\n",
    "        Recursive DFS:\n",
    "          1. If already seen, return immediately.\n",
    "          2. Mark as seen.\n",
    "          3. Ask subclass for children (and record node in order).\n",
    "          4. Recurse on each child.\n",
    "        \"\"\"\n",
    "\n",
    "        # 1) base case\n",
    "        if node in self.visited:\n",
    "            return\n",
    "\n",
    "        # 2) mark visited\n",
    "        self.visited.add(node)\n",
    "\n",
    "        # 3) get children (subclass must record node in self.order here)\n",
    "        children = self.visit_and_get_children(node)\n",
    "\n",
    "        # 4) recurse\n",
    "        for child in children:\n",
    "            self.dfs_visit(child)\n",
    "    \n",
    "    def bfs_search(self,node):\n",
    "        self.visited.clear()\n",
    "        self.order.clear()\n",
    "        queue=deque()\n",
    "        queue.append(node)\n",
    "        self.bfs_visit(queue)\n",
    "        return self.order\n",
    "    \n",
    "    def bfs_visit(self,queue):\n",
    "        size=len(queue)\n",
    "        if size==0:\n",
    "            return\n",
    "        for i in range(size):\n",
    "            node=queue.popleft()\n",
    "            if node in self.visited:\n",
    "                continue\n",
    "            self.visited.add(node)\n",
    "            children=self.visit_and_get_children(node)\n",
    "            for child in children:\n",
    "                queue.append(child)\n",
    "        self.bfs_visit(queue)\n",
    "\n",
    "class MatrixSearcher(GraphSearcher):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        df should be a square DataFrame whose index and columns\n",
    "        are the same set of node labels, and entries are 0/1.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "\n",
    "    def visit_and_get_children(self, node):\n",
    "        \"\"\"\n",
    "        1) append the node to the visitation order\n",
    "        2) look across df.loc[node] for entries == 1\n",
    "           and return those column‐labels as children\n",
    "        \"\"\"\n",
    "        # record the visitation\n",
    "        self.order.append(node)\n",
    "\n",
    "        # df.loc[node] is a Series of 0/1; .items() yields (col_label, value)\n",
    "        children = [\n",
    "            col\n",
    "            for col, val in self.df.loc[node].items()\n",
    "            if val == 1\n",
    "        ]\n",
    "        return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f15e26-a519-4430-972d-09ec0c4f1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2=MatrixSearcher(df)\n",
    "m2.bfs_search(\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6e9db-f3a0-42dc-afe1-88d782afad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([\n",
    "    [0,1,0,1],\n",
    "    [0,0,1,0],\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0],\n",
    "], index=[\"A\", \"B\", \"C\", \"D\"], columns=[\"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "m3=MatrixSearcher(df2)\n",
    "m3.bfs_search(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d57060-191c-4ad4-ac18-0cfe5cc63f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrape\n",
    "from scrape import WebSearcher\n",
    "fs = scrape.FileSearcher()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116945-a03c-4053-80ce-c5bd669417a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fs.visit_and_get_children(\"1.txt\"), fs.order, fs.concat_order())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278a40d3-bd98-454f-aee6-278147201115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = None\n",
    "\n",
    "def browser():\n",
    "    global driver\n",
    "\n",
    "    if not driver:\n",
    "        os.system(\"pkill -f -9 chromium\")\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless=new\")\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d446158f-e2b1-4ea0-92b7-ccac5c458559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n",
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://34.67.179.64:5000/Node_2.html', 'http://34.67.179.64:5000/Node_4.html']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n",
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n",
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n",
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n",
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n",
      "/home/varda/labs-and-projects/projects/mp4/scrape.py:166: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(self.driver.page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<scrape.WebSearcher object at 0x7f4c2a0aba00>\n",
      "    clue   latitude   longitude                          description\n",
      "0      1  43.089034  -89.416128              Picnic Point in Madison\n",
      "1      7  38.105507  126.910613               Silver Beach in Hawaii\n",
      "2      1  65.044901  -16.712836  Shore of a Volcanic Lake in Iceland\n",
      "3      3  48.860945    2.335773                  The Louvre in Paris\n",
      "4      5  37.434183 -122.321990      Redwood forest in San Francisco\n",
      "5      8  51.180315   -1.829659                 Stonehenge in the UK\n",
      "6      2  27.987586   86.925002                 Mt. Everest in Nepal\n",
      "7      4  34.134117 -118.321495                 Hollywood Sign in LA\n",
      "8      5  38.655100   90.061800                 Cahokia Mounds in IL\n",
      "9      9  40.748400   73.985700          Empire State Building in NY\n",
      "10     4  29.975300   31.137600        Great Sphinx of Giza in Egypt\n",
      "11     1  47.557600   10.749800     Neuschwanstein Castle in Germany\n",
      "12     5  38.624700   90.184800        The Gateway Arch in St. Louis\n",
      "13     3  30.328500   35.444400                      Petra in Jordan\n",
      "14     2  41.480800   82.683400                    Cedar Point in OH\n",
      "15     6  43.070010  -89.409450          Quick Trip on Monroe Street\n"
     ]
    }
   ],
   "source": [
    "driver = browser()\n",
    "\n",
    "# TODO: fill the value of VM_IP as your VMs IP address\n",
    "VM_IP = '34.67.179.64'\n",
    "start_url = f\"http://{VM_IP}:5000/Node_1.html\"\n",
    "\n",
    "s = WebSearcher(driver)\n",
    "print(s.visit_and_get_children(start_url))\n",
    "\n",
    "s = WebSearcher(driver)\n",
    "s.bfs_search(start_url)\n",
    "print(s)\n",
    "print(s.table())\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84655764-890b-49dd-867a-dfedf5fc6752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
